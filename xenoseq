#!/bin/bash
#
#
########

SCRIPT_PATH=`dirname "$0"`; SCRIPT_PATH=`eval "cd \"$SCRIPT_PATH\" && pwd"`
source $SCRIPT_PATH/xenoseq_bin/functions.sh;

ORANGE='\033[0;33m' 	# WARNINGS
RED='\033[0;31m'	# ERRORS
GREEN='\033[0;32m'	# COMPLETION
BLUE='\033[0;36m'	# FILES
PRP='\033[0;35m'	# COSMETIC
GREY='\033[0;90m'	# CMD message
NC='\033[0m' # No Color

version="1.0.1"         # Stable release of previous changes.

echo -e "\n${ORANGE} __    __                                                             ";
echo "/  |  /  |                                                            ";
echo "AT |  GC |  ______   _______    ______    _______   ______    ______  ";
echo "GG  \/AG/  /      \ /       \  /      \  /       | /      \  /      \ ";
echo " TA  TT<  /GATACT  |TAAATGG  |/CCGTAA  |/AATAAAS/ /ATTTCT  |/ATGTTA  |";
echo "  TGAC  \ AA    GA |TG |  GG |AG |  AG |TT      \ TT    CG |GA |  AT |";
echo " AA /AT  |GATCCCGT/ TA |  AA |CG \__AG | GGAACT  |TACGGGTA/ GT \__AT |";
echo "AA |  GC |CC       |GA |  GT |GC    GT/ /     GG/ TA       |AG    AT |";
echo "GG/   TG/  GTAGGCC/ CA/   TT/  TAAATG/  ATGCGCG/   ATGCAAT/  AGGGTTT |";
echo "                                                                  AA |";
echo "                                                                  AA |";
echo -e "                                                                  AA/ ${NC}\n";
echo -e "----------------------------------------------------------------------"
echo -e "                          (XENOSEQ v${version})                            "
echo -e "----------------------------------------------------------------------\n"

#OPTS
output="Xenoseq_default"
path_to_reads="samples/reads"
read_suffix="_R*.fq"
trace=false
link=false
force_relink=false
metadata=""
jobs=4
cores=4
max_assembly_jobs=4
assembly_cores=4
blength=300
bpid=97
xeno_filename="xenotypic_contigs"

print_usage() {
	echo -e "xenoseq v${version}\n"
	echo -e "contact: bramvandijk88@gmail.com\n"
	echo -e "Usage:\n\t xenoseq -m <meta_data_tsv> -o <output_dir> -c <num_cores> -t"
	echo -e "Mandatory:
	-m/--metadata\t\tFile containing the metadata (tsv file with query-reference sets)
Optional options:
	-p/--path_to_reads <STRING> \tPath to reads for samples in metadata (default = $path_to_reads)
	-r/--read_suffix <STRING> \tRead suffix for paired files in metadata (e.g. _R*.fq for using _R1.fq and _R2.fq) (default = ${read_suffix})
	-l/--link\t\t\tAfter detecting unique contigs, attempt to link them to other reference samples.
	-t/--trace\t\t\tAfter detecting xenotypic contigs, trace them across all samples.
	-c/--cores <INT>\t\tNumber of CPUs to use for smaller tasks (passed on to bwa, samtools, etc.) (default = ${cores})
	-C/--assembly_cores <INT>\t\tNumber of CPUs to use for assembly (megahit) (default = ${cores})
	-j/--jobs  <INT>\t\tMaximum number of parallel jobs (default = ${jobs})
	-J/--max_assembly_jobs  <INT>\tMaximum number of parallel jobs for assembly (default = $max_assembly_jobs)
	-o/--output <STRING>\t\tOutput directory to put all the data
	-L/--alignment_length\t\tMinimal alignment length to link unique sequences to other reference samples.
	-P/--alignment_pid\t\tMinimal percent identity to link unique sequences to other reference samples.
	-f/--force_relink\t\tLink unique sequences to reference samples, even when this step is already performed.\n"
}


command=""

while [ $# -gt 0 ]; do
	if [[ $1 =~ ^(-h|-help|--h|--help)$ ]] || [ -z "$1" ]; then
		print_usage;
		exit 1;
	elif [[ $1 =~ ^(-m|--metadata)$ ]]; then
		metadata=("$2")
	elif [[ $1 =~ ^(-o|--output)$ ]]; then
		output=("$2")
	elif [[ $1 =~ ^(-t|--trace)$ ]]; then
		trace=true
	elif [[ $1 =~ ^(-l|--link)$ ]]; then
		link=true
	elif [[ $1 =~ ^(-c|--cores)$ ]]; then
		cores=("$2")
	elif [[ $1 =~ ^(-C|--assembly_cores)$ ]]; then
		assembly_cores=("$2")
	elif [[ $1 =~ ^(-J|--max_assembly_jobs)$ ]]; then
		max_assembly_jobs=("$2")
	elif [[ $1 =~ ^(-f|--force_relink)$ ]]; then
		force_relink=true
	elif [[ $1 =~ ^(-p|--path_to_reads)$ ]]; then
		path_to_reads=("$2")
	elif [[ $1 =~ ^(-r|--read_suffix)$ ]]; then
		read_suffix=("$2")
	elif [[ $1 =~ ^(-j|--jobs)$ ]]; then
		jobs=("$2")
	elif [[ $1 =~ ^(-L|--alignment_length)$ ]]; then
		blength=("$2")
	elif [[ $1 =~ ^(-P|--alignment_pid)$ ]]; then
		bpid=("$2")
	elif [[ $1 == *"-"* ]]; then
		v="${1/-/}"
		declare $v="$2"
	fi
	shift
done

max_load=$(( $jobs * $cores ));
max_load_assembly=$(( $max_assembly_jobs * $assembly_cores ));
nproc=$(nproc --all)
if [ "$max_load" -gt "$nproc" ]; then
	echo -e "[${RED}xenoseq_warn${NC}     $(date +%d-%m_%H:%M:%S)] ${RED}the max cpus in use ($max_load) exceeds the number of cpus on this machine (${nproc}). hoping for the best. ¯\\\_(\ツ)_/¯${NC}"
fi;
if [ "$max_load_assembly" -gt "$nproc" ]; then
	echo -e "[${RED}xenoseq_warn${NC}     $(date +%d-%m_%H:%M:%S)] ${RED}the max cpus in use for assembly ($max_load_assembly) exceeds the number of cpus on this machine (${nproc}). hoping for the best. ¯\\\_(\ツ)_/¯${NC}"
fi;
############
###### Parsing meta data ######
############
echo -e "[xenoseq_main     $(date +%d-%m_%H:%M:%S)] ${BLUE}STEP 1) PARSING METADATA${NC}"

if [[ $metadata == "" ]]; then
	print_usage
	exit 1
elif [[ ! -f $metadata ]]; then
	echo -en "\n[ERROR] Metadata file (${metadata}) does not exist.\n\n"
	exit 1
fi
parse_metadata $metadata

echo -en "[xenoseq_main     $(date +%d-%m_%H:%M:%S)] Checking if query-reads exist with suffix ${BLUE}\"${read_suffix}\"${NC} in path ${BLUE}\"${path_to_reads}\"${NC}"
for (( i=0; i<${#query_samples[@]}; i++ )); do
	for file in ${path_to_reads}/${query_samples[$i]}${read_suffix}; do
		if [ ! -f $file ]; then
			echo -en "\t[ERROR]\n\nReads for \"${query_samples[$i]}\" not found at ${BLUE}${path_to_reads}${NC}/${query_samples[$i]}${BLUE}${read_suffix}${NC}. Try setting the correct path (-p) and suffix (-r) to locate your reads \n\n"
			exit 1
		fi
	done
done
echo -e "\t${GREEN}[OK]${NC}"
echo -en "[xenoseq_main     $(date +%d-%m_%H:%M:%S)] Checking if subject-reads exist with suffix ${BLUE}\"$read_suffix\"${NC} in path ${BLUE}\"${path_to_reads}\"${NC}"
for (( i=0; i<${#reference_samples[@]}; i++ )); do
	for file in ${path_to_reads}/${reference_samples[$i]}${read_suffix}; do
		if [ ! -f $file ]; then
			echo -en "\t[ERROR]\n\nReads for \"${reference_samples[$i]}\" not found at ${BLUE}${path_to_reads}${NC}/${reference_samples[$i]}${BLUE}${read_suffix}${NC}. Try setting the correct path (-p) and suffix (-r) to locate your reads \n\n"
			exit 1
		fi
	done
done
echo -e "\t${GREEN}[OK]${NC}"

# Make the global output directory
mkdir -p ${output}/
mkdir -p ${output}/logs

echo -e "[xenoseq_main     $(date +%d-%m_%H:%M:%S)] ${BLUE}STEP 2) PREPARING ALL SAMPLES${NC}"

############
###### Prepare reference samples ######
############

trim_jobs=()
asse_jobs=()
db_jobs=()
for (( i=0; i<${#reference_samples[@]}; i++ )); do
	echo -e "\n[xenoseq_prep     $(date +%d-%m_%H:%M:%S)] Generating jobs for preparation of reference ${reference_samples[$i]}" # Note to user, to just run this part instead of the whole pipeline, use 'xenoseq_find'

	r1=$(ls ${path_to_reads}/${reference_samples[$i]}${read_suffix} | head -n 1)
	r2=$(ls ${path_to_reads}/${reference_samples[$i]}${read_suffix} | tail -n 1)
	mkdir -p $output/${reference_samples[$i]}/reads
	mkdir -p $output/${reference_samples[$i]}/logs

	trim $r1 $r2 $output/${reference_samples[$i]}/reads/merged_reads.fasta #set current command to trim
	if [[ ! " ${trim_jobs[*]} " =~ " ${command} " ]]; then trim_jobs+=($command); fi
	assemble_mh $output/${reference_samples[$i]}/reads/merged_reads.fasta 100 $output/${reference_samples[$i]}/assembly
	if [[ ! " ${asse_jobs[*]} " =~ " ${command} " ]]; then asse_jobs+=($command); fi
	blastdb $output/${reference_samples[$i]}/assembly/final.contigs.fa 
	if [[ ! " ${db_jobs[*]} " =~ " ${command} " ]]; then db_jobs+=($command); fi
	bwa_index $output/${reference_samples[$i]}/assembly/final.contigs.fa
	if [[ ! " ${db_jobs[*]} " =~ " ${command} " ]]; then db_jobs+=($command); fi;
done

for (( i=0; i<${#query_samples[@]}; i++ )); do
	echo -e "\n[xenoseq_prep     $(date +%d-%m_%H:%M:%S)] Generating jobs for preparation of query ${query_samples[$i]}" # Note to user, to just run this part instead of the whole pipeline, use 'xenoseq_find'

	r1=$(ls ${path_to_reads}/${query_samples[$i]}${read_suffix} | head -n 1)
	r2=$(ls ${path_to_reads}/${query_samples[$i]}${read_suffix} | tail -n 1)
	mkdir -p $output/${query_samples[$i]}/reads
	mkdir -p $output/${query_samples[$i]}/logs

	trim $r1 $r2 $output/${query_samples[$i]}/reads/merged_reads.fasta #set current command to trim
	if [[ ! " ${trim_jobs[*]} " =~ " ${command} " ]]; then trim_jobs+=($command); fi
	assemble_mh $output/${query_samples[$i]}/reads/merged_reads.fasta 100 $output/${query_samples[$i]}/assembly
	if [[ ! " ${asse_jobs[*]} " =~ " ${command} " ]]; then asse_jobs+=($command); fi
	blastdb $output/${query_samples[$i]}/assembly/final.contigs.fa 
	if [[ ! " ${db_jobs[*]} " =~ " ${command} " ]]; then db_jobs+=($command); fi
	bwa_index $output/${query_samples[$i]}/assembly/final.contigs.fa
	if [[ ! " ${db_jobs[*]} " =~ " ${command} " ]]; then db_jobs+=($command); fi;
done

num_trim=$(echo ${trim_jobs[*]} | tr -cd ';' | wc -c)
num_asse=$(echo ${asse_jobs[*]} | tr -cd ';' | wc -c)
num_db=$(echo ${db_jobs[*]} | tr -cd ';' | wc -c)

echo -e "\n[xenoseq_prep     $(date +%d-%m_%H:%M:%S)] Running ${num_trim} trimming jobs in parallel ($jobs jobs at a time)" # Note to user, to just run this part instead of the whole pipeline, use 'xenoseq_find'
echo ${trim_jobs[*]} | tr ';' '\n' | parallel -j $jobs > /dev/null 2>&1
echo -e "[xenoseq_prep     $(date +%d-%m_%H:%M:%S)] ${GREEN}Trimming/merging with fastp completed succesfully for ${num_trim} jobs${NC}"

echo -e "\n[xenoseq_prep     $(date +%d-%m_%H:%M:%S)] Running ${num_asse} assembly jobs in parallel ($max_assembly_jobs jobs at a time)" # Note to user, to just run this part instead of the whole pipeline, use 'xenoseq_find'
echo ${asse_jobs[*]} | tr ';' '\n' | parallel -j $max_assembly_jobs > /dev/null 2>&1
echo -e "[xenoseq_prep     $(date +%d-%m_%H:%M:%S)] ${GREEN}Assembly with megahit completed succesfully for ${num_asse} jobs${NC}"
 
echo -e "\n[xenoseq_prep     $(date +%d-%m_%H:%M:%S)] Running ${num_db} database (blast, bwa) jobs in parallel ($jobs jobs at a time)" # Note to user, to just run this part instead of the whole pipeline, use 'xenoseq_find'
echo ${db_jobs[*]} | tr ';' '\n' | parallel -j $jobs > /dev/null 2>&1
echo -e "[xenoseq_prep     $(date +%d-%m_%H:%M:%S)] ${GREEN}Setting up all databases (blast, bwa) completed for ${num_db} jobs${NC}"

echo -e "[xenoseq_main     $(date +%d-%m_%H:%M:%S)] ${BLUE}STEP 3) MAPPING TO REFERENCE${NC}" # Note to user, to just run this part instead of the whole pipeline, use 'xenoseq_find'

############
###### Mapping to queries and assembling unique reads into contigs (unique_contigs.fasta) ######
############

find_jobs=()
for (( i=0; i<${#query_samples[@]}; i++ )); do
	echo -e "\n[xenoseq_find     $(date +%d-%m_%H:%M:%S)] Looking for unique/xenotypic contigs in ${query_samples[$i]}" # Note to user, to just run this part instead of the whole pipeline, use 'xenoseq_find'

	r1=$(ls ${path_to_reads}/${query_samples[$i]}${read_suffix} | head -n 1)
	r2=$(ls ${path_to_reads}/${query_samples[$i]}${read_suffix} | tail -n 1)
	reads=$output/${query_samples[$i]}/reads/merged_reads.fasta
	#trim $r1 $r2 $reads #depricated due to parallelisation changes
	index=$output/${reference_samples[$i]}/assembly/final.contigs.fa
	mkdir -p $output/${query_samples[$i]}/read_mapping
	out="$output/${query_samples[$i]}/read_mapping/${query_samples[$i]}_to_${reference_samples[$i]}"
	bwa_map $index $reads $out
	unmapped_to_fasta $out.sorted.bam ${reference_samples[$i]}
	assemble_mh $output/${query_samples[$i]}/reads/unique_reads.fasta 300 $output/${query_samples[$i]}/unique_assembly
	if [[ ! " ${find_jobs[*]} " =~ " ${command} " ]]; then find_jobs+=($command); fi
done

echo -e "\n[xenoseq_find     $(date +%d-%m_%H:%M:%S)] Running assembly of all unique reads in parallel ($jobs jobs at a time)"
echo ${find_jobs[*]} | tr ';' '\n' | parallel --keep-order -j $jobs 2> /dev/null

or (( i=0; i<${#query_samples[@]}; i++ )); do
	seqkit sort -l -r $output/${query_samples[$i]}/unique_assembly/final.contigs.fa > $output/${query_samples[$i]}/unique_contigs.fasta 2> $output/logs/seqkit.log
	if [[ $link = "true" || $force_relink = "true" ]]; then
		if [[ $force_relink = "true" ]]; then 
			xeno_filename="xenotypic_contigs_L${blength}_P${bpid}"
		fi
		unique_refs=($(echo "${reference_samples[@]}" | tr ' ' '\n' | sort -u | tr '\n' ' '))
		for (( j=0; j<${#unique_refs[@]}; j++ )); do
			if [ ! $j -eq $i ]; then
				if [ -s $output/${query_samples[$i]}/unique_contigs.fasta ]; then
					index=$output/${reference_samples[$j]}/assembly/final.contigs.fa
					out="$output/${query_samples[$i]}/read_mapping/${query_samples[$i]}_to_${reference_samples[$j]}"
					bwa_map $index $reads $out
					samtools_coverage $out
					ref="${reference_samples[$j]}"
					link_contig $output/${query_samples[$i]}/unique_contigs.fasta $index $output/${query_samples[$i]}/unique_contig_links_to_${reference_samples[$j]}.tbl
				fi
			fi
		done
		if ls $output/${query_samples[$i]}/unique_contig_links_to_*.tbl 1> /dev/null 2>&1; then
			cat $output/${query_samples[$i]}/unique_contig_links_to_*.tbl > $output/${query_samples[$i]}/unique_contig_all_links_L${blength}_P${bpid}.tbl
			rm -f $output/${query_samples[$i]}/unique_contig_links_to_*.tbl
			cat $output/${query_samples[$i]}/unique_contig_all_links_L${blength}_P${bpid}.tbl | cut -f1 > $output/${query_samples[$i]}/${xeno_filename}.txt
			seqkit grep -f $output/${query_samples[$i]}/${xeno_filename}.txt $output/${query_samples[$i]}/unique_contigs.fasta -o $output/${query_samples[$i]}/${xeno_filename}.fasta 2> $output/logs/xenotypic.log
		fi
	fi
	num_uniq=0
	if [ -f $output/${query_samples[$i]}/unique_contigs.fasta ]; then num_uniq=$(grep -c '>' $output/${query_samples[$i]}/unique_contigs.fasta); fi
	num_xenos=0
	if [ -f $output/${query_samples[$i]}/${xeno_filename}.fasta ]; then num_xenos=$(grep -c '>' $output/${query_samples[$i]}/${xeno_filename}.fasta); fi
	if [ $link == "true" ]; then 
		echo -e "[xenoseq_link     $(date +%d-%m_%H:%M:%S)]${PRP} Found $num_uniq unique contigs in ${query_samples[$i]}. $num_xenos of these are xenotypic. ${NC}"
	else 
		echo -e "[xenoseq_find     $(date +%d-%m_%H:%M:%S)]${PRP} Found $num_uniq unique contigs in ${query_samples[$i]}. Skipping xenoseq_link (-l not set) ${NC}"
	fi

done

############
###### Tracing across samples ######
############ 

if [ $trace == "true" ] ; then
	echo -e "[xenoseq_main     $(date +%d-%m_%H:%M:%S)] ${BLUE}STEP 4) TRACING UNIQUE/XENOTYPIC SEQUENCES${NC}"

	for (( i=0; i<${#query_samples[@]}; i++ )); do

		if [ -s $output/${query_samples[$i]}/unique_contigs.fasta ]; then
			echo -e "\n[xenoseq_trace    $(date +%d-%m_%H:%M:%S)] Tracing unique contigs from ${query_samples[$i]} across all samples." 
			bwa_index $output/${query_samples[$i]}/unique_contigs.fasta
			for (( j=0; j<${#query_samples[@]}; j++ )); do
				index=$output/${query_samples[$i]}/unique_contigs.fasta
				reads="$output/${query_samples[$j]}/reads/merged_reads.fasta"
				out="$output/${query_samples[$j]}/read_mapping/${query_samples[$j]}_to_unique_from_${query_samples[$i]}"
				bwa_map $index $reads $out
				if [ ! -f ${out}_coverage.txt ]; then
					samtools_coverage $out
					sed -i "s/$/\t${query_samples[$j]}/" ${out}_coverage.txt
					tail -n+2 ${out}_coverage.txt >> $output/${query_samples[$i]}/unique_coverage.txt
				fi
			done
			for (( j=0; j<${#reference_samples[@]}; j++ )); do
				index=$output/${query_samples[$i]}/unique_contigs.fasta
				mkdir -p $output/${reference_samples[$j]}/read_mapping
				if [ -s $output/${query_samples[$i]}/unique_contigs.fasta ]; then
					reads="$output/${reference_samples[$j]}/reads/merged_reads.fasta"
					out="$output/${reference_samples[$j]}/read_mapping/${reference_samples[$j]}_to_unique_from_${query_samples[$i]}"
					bwa_map $index $reads $out
					if [ ! -f ${out}_coverage.txt ]; then
						samtools_coverage $out
						sed -i "s/$/\t${reference_samples[$j]}/" ${out}_coverage.txt
						tail -n+2 ${out}_coverage.txt >> $output/${query_samples[$i]}/unique_coverage.txt
					fi
				fi
			done
		rm -rf $output/${query_samples[$i]}/unique_contigs.fasta.*
		sed -i "1i\contig\tstartpos\tendpos\tnumreads\tcovbases\tcoverage\tmeandepth\tmeanbaseq\tmeanmapq\tsample" $output/${query_samples[$i]}/unique_coverage.txt
		fi 

		if [ -s $output/${query_samples[$i]}/${xeno_filename}.fasta ]; then
			echo -e "\n[xenoseq_trace    $(date +%d-%m_%H:%M:%S)] Tracing xenotypic contigs from ${query_samples[$i]} across all samples." 
			bwa_index $output/${query_samples[$i]}/${xeno_filename}.fasta
			for (( j=0; j<${#query_samples[@]}; j++ )); do
				index=$output/${query_samples[$i]}/${xeno_filename}.fasta
				reads="$output/${query_samples[$j]}/reads/merged_reads.fasta"
				out="$output/${query_samples[$j]}/read_mapping/${query_samples[$j]}_to_${xeno_filename}_from_${query_samples[$i]}"
				bwa_map $index $reads $out
				if [ ! -f ${out}_coverage.txt ]; then
					samtools_coverage $out
					sed -i "s/$/\t${query_samples[$j]}/" ${out}_coverage.txt
					tail -n+2 ${out}_coverage.txt >> $output/${query_samples[$i]}/${xeno_filename}_coverage.txt
				fi
			done
			for (( j=0; j<${#reference_samples[@]}; j++ )); do
				index=$output/${query_samples[$i]}/${xeno_filename}.fasta
				mkdir -p $output/${reference_samples[$j]}/read_mapping
				if [ -s $output/${query_samples[$i]}/${xeno_filename}.fasta ]; then
					reads="$output/${reference_samples[$j]}/reads/merged_reads.fasta"
					out="$output/${reference_samples[$j]}/read_mapping/${reference_samples[$j]}_to_${xeno_filename}_from_${query_samples[$i]}"
					bwa_map $index $reads $out
					if [ ! -f ${out}_coverage.txt ]; then
						samtools_coverage $out
						sed -i "s/$/\t${reference_samples[$j]}/" ${out}_coverage.txt
						tail -n+2 ${out}_coverage.txt >> $output/${query_samples[$i]}/${xeno_filename}_coverage.txt
					fi
				fi
			done
		rm -rf $output/${query_samples[$i]}/xenotypic_contigs.fasta.*
		sed -i "1i\contig\tstartpos\tendpos\tnumreads\tcovbases\tcoverage\tmeandepth\tmeanbaseq\tmeanmapq\tsample" $output/${query_samples[$i]}/${xeno_filename}_coverage.txt
		fi 
	done
fi

echo -e "[xenoseq_main     $(date +%d-%m_%H:%M:%S)] ${GREEN}Xenoseq finished.${NC}"
